{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgHB6cYTBNWMExMsSKkAhO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjleece/ai-reflector/blob/main/wjleece_Langchain_Reflector_2_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U --quiet  langchain langgraph\n",
        "%pip install -U --quiet tavily-python\n",
        "%pip install -U --quiet fireworks-ai\n",
        "%pip install -U --quiet langchain_fireworks"
      ],
      "metadata": {
        "id": "W0C8q_oYy3zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import re\n",
        "from langchain_fireworks import Fireworks\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "gcO7OpEJzppr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_env_var(var: str) -> None:\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"Enter {var}: \")\n",
        "\n",
        "# Set up environment variables\n",
        "set_env_var(\"LANGCHAIN_API_KEY\")\n",
        "set_env_var(\"FIREWORKS_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Reflection\""
      ],
      "metadata": {
        "id": "oBbUwmDEzsCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ChatFireworks\n",
        "base_llm = Fireworks(\n",
        "    model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=16384\n",
        ")\n",
        "\n",
        "reflector_llm = Fireworks(\n",
        "    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=32768\n",
        ")\n"
      ],
      "metadata": {
        "id": "8wVGxS-Jz79C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompts\n",
        "essay_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an essay assistant tasked with writing excellent 5-paragraph essays. \"\n",
        "               \"Generate the best essay possible for the user's request. \"\n",
        "               \"If you receive feedback or a critique of the essay, incorporate the feedback and rewrite the essay. \"\n",
        "               \"If you rewrite the essay, preface it with 'Revised Essay:' to make it clear that what follows is a revision. \"\n",
        "               \"If you have no feedback or critiques, you do not need to rewrite the essay.\"),\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "])\n",
        "\n",
        "reflection_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a teacher grading an essay submission. Generate critique and recommendations for the user's submission. \"\n",
        "               \"Provide detailed recommendations, including requests for length, depth, style, etc. \"\n",
        "               \"Make sure to include an overall score from 0 - 100 prefaced by the indicator 'Score:' for the essay prominently as either the first line or title of the critique.\"\n",
        "               \"Make sure the score is written as a number and not as a fraction.\"),\n",
        "    MessagesPlaceholder(variable_name=\"messages\")\n",
        "])"
      ],
      "metadata": {
        "id": "ew1PJnjZz_HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jemmcbGPyniV"
      },
      "outputs": [],
      "source": [
        "# Create LLMChains\n",
        "generate_chain = essay_prompt | base_llm\n",
        "\n",
        "reflect_chain = reflection_prompt | reflector_llm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_score(reflection):\n",
        "    print(\"Debug: Reflection content:\", reflection)  # Debug statement\n",
        "\n",
        "    # Look for patterns like \"Score: X\" or \"Score: X/Y\" or \"X/100\" or just a number as the LLM returns all types of values, even when explicitly told not to return certain formats\n",
        "    score_patterns = [\n",
        "        r\"Score:\\s*(\\d+)(?:/\\d+)?\",\n",
        "        r\"(\\d+)/100\",\n",
        "        r\"^(\\d+)$\"\n",
        "    ]\n",
        "\n",
        "    for pattern in score_patterns:\n",
        "        match = re.search(pattern, reflection, re.MULTILINE)\n",
        "        if match:\n",
        "            try:\n",
        "                score = int(match.group(1))\n",
        "                print(\"Debug: Extracted score:\", score)  # Debug statement\n",
        "                return score\n",
        "            except ValueError:\n",
        "                print(\"Debug: Failed to convert matched score to integer\")\n",
        "\n",
        "    print(\"Debug: No valid score pattern found\")\n",
        "    print(\"Error extracting score. Using None.\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "e7A-WdJju-ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay = \"\"\n",
        "\n",
        "def generate_and_reflect_essay():\n",
        "\n",
        "    request = \"Write an essay on the history of Canada.\" #time to learn about your northern neighbour\n",
        "\n",
        "   #write initial AI-generated essay\n",
        "    essay = generate_chain.invoke({\"messages\": [HumanMessage(content=request)]})\n",
        "\n",
        "\n",
        "    #reflect on initial AI-generated essay\n",
        "    reflection = reflect_chain.invoke({\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=request),\n",
        "            AIMessage(content=essay)\n",
        "        ]\n",
        "    })\n",
        "\n",
        "    #get the essay score\n",
        "    score = extract_score(reflection)\n",
        "\n",
        "    return request, essay, reflection, score"
      ],
      "metadata": {
        "id": "cKU5HXXC0DVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request, essay, reflection, score = generate_and_reflect_essay()"
      ],
      "metadata": {
        "id": "ljOq87Fuws3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request"
      ],
      "metadata": {
        "id": "KZI89nL1wzKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay"
      ],
      "metadata": {
        "id": "ACDViA8Aw4cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reflection"
      ],
      "metadata": {
        "id": "ctTrKDKaw51A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "id": "sIweD_64w7SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate(request, essay, reflection, score):\n",
        "    revised_essay = essay\n",
        "    target_score = 95\n",
        "    revision_count = 0\n",
        "    max_revisions = 10\n",
        "    min_essay_length = 50\n",
        "\n",
        "    while (score is None or score < target_score) and revision_count < max_revisions:\n",
        "        revised_essay = generate_chain.invoke({\"messages\": [\n",
        "            HumanMessage(content=request),\n",
        "            AIMessage(content=revised_essay),\n",
        "            HumanMessage(content=reflection)\n",
        "        ]})\n",
        "\n",
        "        new_essay = revised_essay\n",
        "\n",
        "        words = new_essay.strip().split()\n",
        "        essay_length = len(words)\n",
        "\n",
        "        if essay_length >= min_essay_length:\n",
        "            revised_essay = new_essay\n",
        "            revision_count += 1\n",
        "            print(f\"Revision count: {revision_count}\")\n",
        "            print(f\"Essay length: {essay_length}\")\n",
        "\n",
        "            reflection_response = reflect_chain.invoke({\"messages\": [\n",
        "                HumanMessage(content=request),\n",
        "                AIMessage(content=revised_essay)\n",
        "            ]})\n",
        "            reflection = reflection_response\n",
        "\n",
        "            score = extract_score(reflection)\n",
        "            print(f\"Essay score: {score}\\n\")\n",
        "        else:\n",
        "            print(f\"Generated essay too short ({essay_length} words). Retrying...\")\n",
        "\n",
        "    if revision_count == max_revisions:\n",
        "        print(\"Maximum number of revisions reached.\")\n",
        "\n",
        "    return request, revised_essay, reflection, score"
      ],
      "metadata": {
        "id": "BzAa80_E0KBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    request, essay, reflection, score = generate_and_reflect_essay()\n",
        "    request, revised_essay, reflection, score = iterate(request, essay, reflection, score)\n",
        "    print(f\"Final Essay:\\n{revised_essay}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "t-tKAHWc0LmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}